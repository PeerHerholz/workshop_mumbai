{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nipype Hands-on: How to create an fMRI preprocessing workflow\n",
    "\n",
    "The purpose of this section is that you setup a fMRI pre-processing workflow yourself. We want to highlight that this pipeline is only an abbreviated version of a real fMRI pre-processing pipeline. We took some short cuts to keep the computation time to a minimum. For a more realistic example, check out the Hands-on example from the [Nipype Tutorial](https://miykael.github.io/nipype_tutorial/) or the fully automatic state-of-the-art pre-processing pipeline [fmriprep](http://fmriprep.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Workflow Structure\n",
    "\n",
    "So let's get our hands dirty. First things first, it's always good to know which interfaces you want to use in your workflow and in which order you want to execute them. For this pre-processing workflow, I recommend that we use the following nodes:\n",
    "\n",
    "     1. Extract Brain from Anatomical Image\n",
    "     2. Segment Brain\n",
    "     3. Normalize Brain to MNI-Template\n",
    "     4. Motion Correct Functional Image\n",
    "     5. Coregister Functional Image to Anatomy\n",
    "     6. Normalize Functional Image to MNI-Template\n",
    "     7. Smooth Functional Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "It's always best to have all relevant module imports at the beginning of your script. So let's import what we most certainly need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Node and Workflow object\n",
    "from nipype import Node, Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nodes and Workflow connections\n",
    "\n",
    "Let's create all the nodes that we need! Make sure to specify all relevant inputs and keep in mind which ones you later on need to connect in your pipeline.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "We recommend to create the workflow and establish all it's connections at a later place in your script. This helps to have everything nicely together. But for this hands-on example it makes sense to establish the connections between the nodes as we go.\n",
    "\n",
    "And for this, we first need to create a workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Create the workflow here\n",
    "# Hint: use 'base_dir' to specify where to store the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc = Workflow(name='work_preproc', base_dir='/output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Brain\n",
    "\n",
    "For certain processing steps it's better to just have the brain, without the skull and rest of the head. This can be done by extracting the brain from the anatomical raw image. So let's implement a node that does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import BET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Gunzip node\n",
    "brain_extract_anat = Node(BET(frac=0.2), name='brain_extract_anat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already created the brain extraction node for you. It serves as a template for the other nodes to come."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Anatomical Image\n",
    "\n",
    "For the image coregistration between functional and anatomical images we will need the white matter (WM) segmentation of the anatomical image. So let's implement a node that does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Initiate Segmentation node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "segmentation = Node(FAST(segments=True, no_pve=True, no_bias=True),\n",
    "                    name='segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next step is to connect the `segmentation` node to the rest of the workflow, i.e. the `brain_extract_anat` node from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect Segmentation node to anatomical brain extraction node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(brain_extract_anat, segmentation, [('out_file', 'in_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Anatomical Image to MNI-Template\n",
    "\n",
    "In the end we want to have all data in a common reference space. In MRI this is usually the MNI-Template. This will allow us to compare the brains of different subjects with each other. So let's implement the node that computes the transformation matrix that maps the subject brain onto the template brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import FLIRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Initate normalize node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mni_template = '/templates/MNI152_T1_1mm.nii.gz'\n",
    "normalize = Node(FLIRT(reference=mni_template), name=\"normalize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will connect the input to this node at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction of Functional Image\n",
    "\n",
    "Let us now focus on the functional image. First, let's correct for the motion during data recording. It's normal that a subject moves their head a bit in the scanner. Therefore, an important step in fMRI pre-processing is to correct for this head motion. So let's implement the node that does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import MCFLIRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Initate motion correction node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "motion_correction = Node(MCFLIRT(mean_vol=True,\n",
    "                                 save_plots=True),\n",
    "                         name=\"motion_correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will connect the input to this node at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Coregistration Matrix\n",
    "\n",
    "As a next step we will make sure that the functional images are coregistered to the anatomical image. For this we will use FSL's `FLIRT` function. As we just created a white matter probability map, we can use this together with the a Boundary-Based Registration (BBR) cost function to optimize the image coregistration. As some helpful notes...\n",
    "- use a degree of freedom of 6\n",
    "- specify the cost function as `bbr`\n",
    "- use the `schedule='/usr/share/fsl/5.0/etc/flirtsch/bbr.sch'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import FLIRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Initate coregistration node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "coregistration = Node(FLIRT(dof=6,\n",
    "                            cost='bbr',\n",
    "                            schedule='/usr/share/fsl/5.0/etc/flirtsch/bbr.sch',\n",
    "                            output_type='NIFTI'),\n",
    "                      name=\"coregistration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect coregistration node to the other nodes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(motion_correction, coregistration, [('mean_img', 'in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the `bbr` routine can use the subject specific white matter mask to guide the coregistration. The problem is that the `segmentation` node above gives us back a list of files, i.e. `['CSF_mask', 'GM_mask', 'WM_mask']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks that we're interested in is the last one. Let us therefore write a short function that gives us back the last element of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select WM segmentation file from segmentation output\n",
    "def get_wm(files):\n",
    "    return files[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that we can connect the `segmentation` node to the `coregistration` node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the segmentation node with the coregistration node\n",
    "preproc.connect([(segmentation, coregistration, [(('tissue_class_files', get_wm),\n",
    "                                                  'wm_seg')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Coregistration Matrix to functional image\n",
    "\n",
    "Now that we know the coregistration matrix to correctly overlay the functional mean image on the subject specific anatomy, we need to apply to coregistration to the whole time series. This can be achieved with FSL's `FLIRT` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the isometric voxel resolution you want after coregistration\n",
    "desired_voxel_iso = 4\n",
    "\n",
    "# Apply coregistration warp to functional images\n",
    "apply_coregistration = Node(FLIRT(interp='spline',\n",
    "                                  apply_isoxfm=desired_voxel_iso),\n",
    "                            name=\"apply_coregistration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Important</span>**: As you can see above, we also specified a variable `desired_voxel_iso`. This is very important at this stage, otherwise `FLIRT` will transform your functional images to a resolution of the anatomical image, which will dramatically increase the file size (e.g. to 1-10GB per file). If you don't want to change the voxel resolution, use the `no_resample=True` value instead of `apply_isoxfm=desired_voxel_iso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the ApplyWarp node to all the other nodes\n",
    "preproc.connect([(motion_correction, apply_coregistration, [('out_file', 'in_file')]),\n",
    "                 (coregistration, apply_coregistration, [('out_matrix_file', 'in_matrix_file')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Normalization Matrix to functional image\n",
    "\n",
    "After the functional images were coregistered to the anatomical image we can apply the normalization matrix to get the functional images into MNI-Template space. This step is almost identical as before, so let's not forget the `apply_isoxfm=desired_voxel_iso` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization warp to functional images\n",
    "apply_normalization = Node(FLIRT(interp='spline',\n",
    "                                 apply_isoxfm=desired_voxel_iso,\n",
    "                                 reference=mni_template),\n",
    "                           name=\"apply_normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now connect the `apply_normalization` node to the other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the ApplyWarp node to all the other nodes\n",
    "preproc.connect([(apply_coregistration, apply_normalization, [('out_file', 'in_file')]),\n",
    "                 (normalize, apply_normalization, [('out_matrix_file', 'in_matrix_file')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "Next step is image smoothing. The extend of smoothing depends on what kind of analysis you want to perform later on. For machine learning approaches it is recommended not to smooth too much, so let's choose a smoothing kernel with a `FWHM` parameter of 2mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import Smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Initate smooth node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "smooth = Node(Smooth(fwhm=2), name=\"smooth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect smooth node to normalize node above here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(apply_normalization, smooth, [('out_file', 'in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datainput with `IdentityInterface`, `iterables` and `SelectFiles`\n",
    "\n",
    "This is all nice and well. But so far we don't have any data in our workflow. We could sepcify the required input files manually, but that would be tiresome. So how can we scale this up to multiple subjects and multiple functional images?\n",
    "\n",
    "The solution is [`IdentityInterface`](https://miykael.github.io/nipype_tutorial/notebooks/basic_iteration.html#IdentityInterface-(special-use-case-of-iterables), [`iterables`](https://miykael.github.io/nipype_tutorial/notebooks/basic_iteration.html) and [`SelectFiles`](https://miykael.github.io/nipype_tutorial/notebooks/basic_data_input.html#SelectFiles)! It's rather simple, specify a template and fill-up the placeholder variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SelectFiles\n",
    "from nipype import SelectFiles\n",
    "\n",
    "# String template with {}-based strings\n",
    "anat_template = {'anat': 'sub-{subject_id}/anat/sub-{subject_id}_T1w.nii.gz'}\n",
    "func_template = {'func': 'sub-{subject_id}/func/sub-{subject_id}_task-rest-{task_id}_bold.nii.gz'}\n",
    "\n",
    "# Create SelectFile node for anatomical images\n",
    "select_anat = Node(SelectFiles(anat_template,\n",
    "                               base_directory='/data/dataset',\n",
    "                               sort_filelist=True),\n",
    "                   name='select_anat')\n",
    "\n",
    "# Create SelectFile node for functional images\n",
    "select_func = Node(SelectFiles(func_template,\n",
    "                               base_directory='/data/dataset',\n",
    "                               sort_filelist=True),\n",
    "                   name='select_func')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data template ready we can specify over which subjects and runs the workflow should iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the workflow, let's just look at subject 01\n",
    "subject_list = ['01']\n",
    "\n",
    "# Iterate over the two different functional sessions 'Eye closed' and 'Eyes open'\n",
    "task_list = ['EC', 'EO'] \n",
    "select_func.iterables = [('task_id', task_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to iterate over those two lists and connect the nodes to the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the IdentityInterface\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "\n",
    "info_source = Node(IdentityInterface(fields=['subject_id']),\n",
    "                   name=\"info_source\")\n",
    "info_source.iterables = [('subject_id', subject_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect IdentityInterface and SelectFiles nodes to the rest of the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(info_source, select_anat, [('subject_id', 'subject_id')]),\n",
    "                 (info_source, select_func, [('subject_id', 'subject_id')]),\n",
    "                 (select_anat, brain_extract_anat, [('anat', 'in_file')]),\n",
    "                 (select_anat, normalize, [('anat', 'in_file')]),\n",
    "                 (select_anat, coregistration, [('anat', 'reference')]),\n",
    "                 (select_anat, apply_coregistration, [('anat', 'reference')]),\n",
    "                 (select_func, motion_correction, [('func', 'in_file')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data output with `DataSink`\n",
    "\n",
    "The execution of the workflow will create a lot of temporary files. You will have an additional copy of your MRI images in almost every node. So let's use a `Datasink` to keep only those files that we actually need. Like this we can later on delete everything that is in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink\n",
    "\n",
    "# Initiate the datasink node\n",
    "output_folder = 'datasink'\n",
    "datasink = Node(DataSink(base_directory='/output/',\n",
    "                         container='datasink'),\n",
    "                name=\"datasink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next step is to specify all the output that we want to keep in our output folder `output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.connect([(brain_extract_anat, datasink, [('out_file', 'preproc.@brain')]),\n",
    "                 (segmentation, datasink, [('tissue_class_files', 'preproc.@segments')]),\n",
    "                 (motion_correction, datasink, [('par_file', 'preproc.@motion_parameter')]),\n",
    "                 (normalize, datasink, [('out_file', 'preproc.@norm_anat')]),\n",
    "                 (smooth, datasink, [('smoothed_file', 'preproc.@func')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to run the workflow. The last thing that we need to do is specifying text substitutions for the datasink. If we don't do this, than files might be called `_subject_id_sub-01_task_id_task-rest-EC_bold_flirt_flirt_brain.nii.gz` or similar. To prevent this, we can use `substitutions`. For this, we create a list of tuples: on the left we specify the string that we want to replace and on the right, with what we want to replace it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the following substitutions for the DataSink output\n",
    "substitutions = [('_flirt', ''),\n",
    "                 ('_bold', ''),\n",
    "                 ('_mcf', ''),\n",
    "                 ('T1w_brain_seg_0', 'seg_csf'),\n",
    "                 ('T1w_brain_seg_1', 'seg_gm'),\n",
    "                 ('T1w_brain_seg_2', 'seg_wm'),\n",
    "                 ('.nii.gz.par', '.par'),\n",
    "                 ]\n",
    "\n",
    "# To get rid of the folder '_subject_id_07' and renaming detrend\n",
    "substitutions += [('_subject_id_%s/' % s, '') for s in subject_list]\n",
    "substitutions += [('_task_id_%s' % r, '') for r in task_list]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the workflow\n",
    "\n",
    "Now that we're done. Let's look at the workflow that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preproc output graph\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename='/output/work_preproc/graph.png', width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run the Workflow\n",
    "\n",
    "Now we are ready to run the workflow! Be careful about the `n_procs` parameter if you run a workflow in `'MultiProc'` mode. `n_procs` specifies the number of jobs/cores your computer will use to run the workflow. If this number is too high your computer will try to execute too many things at once and will most likely crash.\n",
    "\n",
    "**Note**: If  you're using a Docker container and FLIRT fails to run without any good reason, you might need to change memory settings in the Docker preferences (4 GB should be enough for this workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect output\n",
    "\n",
    "What did we actually do? Let's look at all the data that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree /output/datasink/preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot... But what did we exactly do? Well, let's investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Extraction of anatomical image\n",
    "\n",
    "First, how well did the brain extraction on the anatomical image work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nilearn.plotting import plot_stat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_file = '/data/dataset/sub-01/anat/sub-01_T1w.nii.gz'\n",
    "anat_brain = '/output/datasink/preproc/sub-01_T1w_brain.nii.gz'\n",
    "\n",
    "plot_stat_map(anat_brain, title='Anatomical Brain Extraction',  cmap='magma', bg_img=anat_file,\n",
    "              display_mode='y', cut_coords=range(-40, 36, 15), dim=-1, colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems great! It was mostly able to extract the brain from the rest of the anatomical image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Segmentation\n",
    "\n",
    "And how well did the brain segmentation work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import numpy as np\n",
    "\n",
    "anat_img = nb.load(anat_file)\n",
    "gm_img = nb.load('/output/datasink/preproc/sub-01_seg_gm.nii.gz')\n",
    "wm_img = nb.load('/output/datasink/preproc/sub-01_seg_wm.nii.gz')\n",
    "csf_img = nb.load('/output/datasink/preproc/sub-01_seg_csf.nii.gz')\n",
    "\n",
    "data = np.stack((np.zeros(anat_img.get_fdata().shape[:3]),\n",
    "                 gm_img.get_fdata(),\n",
    "                 wm_img.get_fdata(),\n",
    "                 csf_img.get_fdata()), axis= -1)\n",
    "\n",
    "label_id = np.argmax(data, axis=-1)\n",
    "segmentation = nb.Nifti1Image(label_id, anat_img.affine, anat_img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_roi\n",
    "plot_roi(segmentation, cmap='Accent', dim=1, annotate=False, bg_img=anat_img,\n",
    "         display_mode='y', title='Image segmentation (gray=CSF; green=GM, blue=WM)',\n",
    "         resampling_interpolation='nearest', cut_coords=range(-40, 36, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomical Normalization\n",
    "\n",
    "We've also computed the transformation matrix to normalize the anatomical image to a MNI template space. Let's see how well this worked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_anat\n",
    "\n",
    "anat_norm = '/output/datasink/preproc/sub-01_T1w.nii.gz'\n",
    "ref_norm = '/templates/MNI152_T1_1mm.nii.gz'\n",
    "\n",
    "# Plot normalized subject anatomy\n",
    "display = plot_anat(anat_norm, title='Normalization to template brain (red outline)',\n",
    "                    display_mode='y', cut_coords=range(-75, 36, 20), dim=-1, colorbar=False,\n",
    "                    resampling_interpolation='nearest', annotate=False)\n",
    "\n",
    "# Overlay in edges GM map\n",
    "display.add_edges(ref_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction\n",
    "\n",
    "How much did the subject move in the scanner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the motion paramters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "par = np.loadtxt('/output/datasink/preproc/sub-01_task-rest-EC.par')\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "axes[0].set_ylabel('rotation (radians)')\n",
    "axes[0].plot(par[0:, :3])\n",
    "axes[1].plot(par[0:, 3:])\n",
    "axes[1].set_xlabel('time (TR)')\n",
    "axes[1].set_ylabel('translation (mm)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motion parameters seem to look ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Image transformations\n",
    "\n",
    "We did many different things to our functional images. Let's take a look how well this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(mean_img('/data/dataset/sub-01/func/sub-01_task-rest-EC_bold.nii.gz'),\n",
    "              title='Raw Image',  cmap='viridis', bg_img=anat_file,\n",
    "              display_mode='z', cut_coords=range(-10, 41, 10), dim=-1, colorbar=False,\n",
    "              annotate=False, threshold=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreg_file = '/output/work_preproc/_subject_id_01/_task_id_EC/coregistration/'\n",
    "coreg_file += 'sub-01_task-rest-EC_bold_mcf.nii.gz_mean_reg_flirt.nii'\n",
    "plot_stat_map(mean_img(coreg_file),\n",
    "              title='Coregistered Image',  cmap='viridis', bg_img=anat_file,\n",
    "              display_mode='z', cut_coords=range(-10, 41, 10), dim=-1, colorbar=False,\n",
    "              annotate=False, threshold=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_file = '/output/work_preproc/_subject_id_01/_task_id_EC/apply_normalization/'\n",
    "norm_file += 'sub-01_task-rest-EC_bold_mcf_flirt_flirt.nii.gz'\n",
    "plot_stat_map(mean_img(norm_file),\n",
    "              title='Normalized Image',  cmap='viridis', bg_img='/templates/MNI152_T1_1mm.nii.gz',\n",
    "              display_mode='z', cut_coords=range(-45, 56, 20), dim=0, colorbar=False,\n",
    "              annotate=False, threshold=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_file = '/output/datasink/preproc/sub-01_task-rest-EC_smooth.nii.gz'\n",
    "plot_stat_map(mean_img(smooth_file),\n",
    "              title='Smoothed Image',  cmap='viridis', bg_img='/templates/MNI152_T1_1mm.nii.gz',\n",
    "              display_mode='z', cut_coords=range(-45, 56, 20), dim=0, colorbar=False,\n",
    "              annotate=False, threshold=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Preprocessing workflow on all subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now that we know that everything works fine we can run the pre-processing pipeline on all three subjects. For this you just need to change the `subject_list` variable and run again the places where this variable is used (i.e. `select_anat.iterables`, `select_func.iterables` and in `DataSink` `substitutions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Update 'subject_list' and its dependencies here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "subject_list = ['01', '02', '03']\n",
    "info_source.iterables = [('subject_id', subject_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "substitutions += [('_subject_id_%s/' % s, '') for s in subject_list]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the workflow again, this time for all subjects in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the preprocessing workflow again, this time with substitutions\n",
    "%time preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of Results\n",
    "\n",
    "To make sure that the pre-processing of all subjects werekd well, let's quickly plot the anatomical brain extraction, as well as the normalized and smoothed functional images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sub in subject_list:\n",
    "\n",
    "    anat_file = '/data/dataset/sub-%s/anat/sub-%s_T1w.nii.gz' % (sub, sub)\n",
    "    anat_brain = '/output/datasink/preproc/sub-%s_T1w_brain.nii.gz' % sub\n",
    "\n",
    "    plot_stat_map(anat_brain, title='Brain Extraction for sub-%s' % sub,  cmap='magma', bg_img=anat_file,\n",
    "                  display_mode='y', cut_coords=range(-40, 36, 15), dim=-1, colorbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sub in subject_list:\n",
    "\n",
    "    smooth_file = '/output/datasink/preproc/sub-%s_task-rest-EC_smooth.nii.gz' % sub\n",
    "    plot_stat_map(mean_img(smooth_file),\n",
    "                  title='Smoothed Image',  cmap='viridis', bg_img='/templates/MNI152_T1_1mm.nii.gz',\n",
    "                  display_mode='z', cut_coords=range(-45, 56, 20), dim=0, colorbar=False,\n",
    "                  annotate=False, threshold=300);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
